{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda activate: c:\\Users\\gamja5th\\anaconda3\\envs\\torch\n",
      "Python version: 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]\n",
      "cv2 version: 4.10.0\n",
      "mediapipe version 0.10.10\n",
      "pandas version: 2.0.3\n",
      "numpy version: 1.24.1\n",
      "torch version: 2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "# conda activate Gseture\n",
    "print('conda activate:', sys.prefix)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"cv2 version:\", cv2.__version__)\n",
    "print(\"mediapipe version\", mp.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 경로 import class명\n",
    "from main_files.CustomDataset import CustomDataset\n",
    "from main_files.model import CNN_LSTM\n",
    "\n",
    "\n",
    "# 필요한 모듈\n",
    "import torch.nn as nn  \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # 진행바\n",
    "from torch.utils.data import Dataset,DataLoader ,random_split\n",
    "from torchinfo import summary # 모델 요약\n",
    "from tensorboardX import SummaryWriter # 텐서보드 (loss,accuracy 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3476 \n",
      "\n",
      "Traing data size: 2781\n",
      "Validation data size: 695 \n",
      "\n",
      "Traing data # of batch: 44\n",
      "Validation # of batch: 11\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "##   데이터셋 생성\n",
    "##\n",
    "\n",
    "dataset=CustomDataset(window_size=30, Folder_dir='./main_data/')\n",
    "\n",
    "# train,test 분리\n",
    "val_ratio=0.2\n",
    "val_size=int(val_ratio*len(dataset))\n",
    "\n",
    "train_size=len(dataset)-val_size\n",
    "train_dataset, val_dataset=random_split(dataset,[train_size,val_size])\n",
    "\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=64,shuffle=True)  # shuffle: 미니배치들이 에폭마다 섞이는 유무.\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=64,shuffle=False)  # shuffle: 미니배치들이 에폭마다 섞이는 유무.\n",
    "\n",
    "print(\"Dataset size:\",len(dataset),'\\n')\n",
    "print(\"Traing data size:\",len(train_dataset))\n",
    "print(\"Validation data size:\",len(val_dataset),'\\n')   \n",
    "print(\"Traing data # of batch:\",len(train_dataloader))\n",
    "print(\"Validation # of batch:\",len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, train_loader,device,optimizer,loss_func,log_interval=10):\n",
    "    model_name.train()\n",
    "    Train_total_loss=0\n",
    "    Train_correct_predictions=0\n",
    "\n",
    "    for batch_idx,(x_train, y_train) in enumerate(tqdm(train_loader)):\n",
    "        # cross entropy의 y는 LongTensor형이어야 함.\n",
    "        y_train=y_train.type(torch.LongTensor)\n",
    "        x_train=x_train.to(device)\n",
    "        y_train=y_train.to(device)\n",
    "\n",
    "\n",
    "\n",
    "        y_predict=model_name(x_train)\n",
    "        \n",
    "        # loss 계산\n",
    "        loss=loss_func(y_predict,y_train.squeeze(dim=-1))\n",
    "        Train_total_loss+=loss.item()\n",
    "\n",
    "        # 정확도 계싼\n",
    "        values, indices = torch.max(y_predict.data, dim=1,keepdim=True)\n",
    "        Train_correct_predictions += (indices == y_train).sum().item()\n",
    "\n",
    "        # 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch_idx % log_interval==0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch,batch_idx*len(x_train),len(train_dataloader.dataset),\n",
    "        #         100.*batch_idx/len(train_dataloader.dataset),loss.item()\n",
    "        #     ))\n",
    "\n",
    "    avg_train_loss=Train_total_loss/len(train_loader.dataset)\n",
    "    Train_accuracy = 100. * Train_correct_predictions / len(train_loader.dataset)\n",
    "    print('Train Epoch: {} Average loss: {:.6f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch, avg_train_loss, Train_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model_name,test_loader,device,loss_func):\n",
    "    model_name.eval()\n",
    "    correct=0\n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        for idx,(x_test,y_test) in enumerate(test_loader):\n",
    "            y_test=y_test.type(torch.LongTensor)\n",
    "            x_test=x_test.to(device)\n",
    "            y_test=y_test.to(device)  # torch.Size([64, 1])\n",
    "            \n",
    "            y_pred=model_name(x_test)\n",
    "            \n",
    "            val_loss+=loss_func(y_pred,y_test.squeeze(dim=-1)).item()\n",
    "\n",
    "            # 정확하게 분류한 샘플 수 계산\n",
    "            values, indices = torch.max(y_pred.data, dim=1,keepdim=True)        \n",
    "            correct += (indices == y_test).sum().item()\n",
    "\n",
    "            # print('y_test :',y_test.shape)     # torch.Size([64, 1])\n",
    "            # print('indices: ',indices.shape)   # torch.Size([64, 1]) \n",
    "\n",
    "    avg_val_loss=val_loss/len(test_loader.dataset)\n",
    "    accuracy = 100 * correct / len(test_loader.dataset)  # 정확도 계산\n",
    "    print('Validation set: Average loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(avg_val_loss, accuracy))\n",
    "    print()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "# 모델 호출\n",
    "CNN_LSTM_model=CNN_LSTM(\n",
    "                input_size=99, \n",
    "                output_size=64,\n",
    "                units=32).to(device)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.Adam(CNN_LSTM_model.parameters(), lr=0.0001)\n",
    "\n",
    "# loss 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# epoch 설정\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gamja5th\\Documents\\24_2_pioneer\\code\\Gesture_Recognition\\main_files\\model.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_LSTM                                 [64, 4]                   --\n",
       "├─Conv1d: 1-1                            [64, 64, 28]              19,072\n",
       "├─ReLU: 1-2                              [64, 64, 28]              --\n",
       "├─LSTM: 1-3                              [64, 28, 32]              12,544\n",
       "├─Linear: 1-4                            [64, 4]                   132\n",
       "├─Softmax: 1-5                           [64, 4]                   --\n",
       "==========================================================================================\n",
       "Total params: 31,748\n",
       "Trainable params: 31,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 56.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.76\n",
       "Forward/backward pass size (MB): 1.38\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 2.27\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(CNN_LSTM_model, (64,30,99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 134.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Average loss: 0.020200, Accuracy: 57.28%\n",
      "Validation set: Average loss: 0.0193, Accuracy: 79.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 414.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Average loss: 0.018427, Accuracy: 89.61%\n",
      "Validation set: Average loss: 0.0176, Accuracy: 97.99%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 495.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Average loss: 0.016698, Accuracy: 98.92%\n",
      "Validation set: Average loss: 0.0162, Accuracy: 98.99%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 433.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Average loss: 0.015650, Accuracy: 99.60%\n",
      "Validation set: Average loss: 0.0152, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 445.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Average loss: 0.014734, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0144, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 449.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Average loss: 0.014102, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0140, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 495.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Average loss: 0.013783, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0137, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 439.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Average loss: 0.013516, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0134, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 422.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 Average loss: 0.013297, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0132, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 492.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 Average loss: 0.013123, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0131, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 499.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 Average loss: 0.012967, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0129, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 511.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 Average loss: 0.012809, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0128, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 460.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 Average loss: 0.012701, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0127, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 379.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 Average loss: 0.012612, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0126, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 516.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 Average loss: 0.012540, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0125, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 431.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 Average loss: 0.012473, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0125, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 494.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 Average loss: 0.012417, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0124, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 485.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 Average loss: 0.012370, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0124, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 396.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 Average loss: 0.012327, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 421.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 Average loss: 0.012288, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0123, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 438.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 Average loss: 0.012252, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0122, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 419.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 Average loss: 0.012221, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0122, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 440.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 Average loss: 0.012193, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0122, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 429.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 Average loss: 0.012168, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0122, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 427.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 Average loss: 0.012144, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 445.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 Average loss: 0.012122, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 448.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 Average loss: 0.012102, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 498.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 Average loss: 0.012084, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 487.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 Average loss: 0.012067, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 475.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 Average loss: 0.012052, Accuracy: 100.00%\n",
      "Validation set: Average loss: 0.0121, Accuracy: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gesture={\n",
    "    0 : 'Palm',\n",
    "    1 : 'Fist',\n",
    "    2 : 'Finger Tip'\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train(\n",
    "        model_name=CNN_LSTM_model, \n",
    "        train_loader=train_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=criterion,\n",
    "        log_interval=1,\n",
    "        device=device,)\n",
    "\n",
    "    evaluate(\n",
    "        model_name=CNN_LSTM_model,\n",
    "        test_loader=val_dataloader,\n",
    "        loss_func=criterion,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN_LSTM_model.state_dict(), './main_models/model_dict().pt')\n",
    "torch.save(CNN_LSTM_model, './main_models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이해안되는 부분 확인중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[0.0168, 0.3880, 0.9685],\n",
      "        [0.9958, 0.9044, 0.3451],\n",
      "        [0.5561, 0.8403, 0.7750],\n",
      "        [0.7458, 0.1477, 0.5786]])\n",
      "tensor([[0.9685],\n",
      "        [0.9958],\n",
      "        [0.8403],\n",
      "        [0.7458]])\n",
      "tensor([[2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 예측 출력을 나타내는 무작위 텐서 생성 (예시)\n",
    "# 가정: 모델의 출력이 3개의 클래스를 분류하며, 배치 크기가 4인 경우\n",
    "y_pred = torch.rand(4, 3)\n",
    "\n",
    "# y_pred 텐서의 내용 확인\n",
    "print(y_pred.shape)\n",
    "print(y_pred)\n",
    "\n",
    "# 각 샘플에 대한 최대 클래스 인덱스 찾기\n",
    "values, indices = torch.max(y_pred,dim=1, keepdim=True)\n",
    "# dim=1: 행을 따라 최대값 찾기, dim=0: 열을 따라 최대값 찾기\n",
    "# keepdim=True: 출력 텐서각각을 크기가1인 차원으로 유지함.\n",
    "# keepdim=False: 출력 텐서 각각의 크기가 1인 차원을 삭제함.\n",
    "\n",
    "\n",
    "# predicted 텐서의 내용 확인\n",
    "print(values)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배움\n",
    "\n",
    "1. .item()  : 텐서의 값을 일반 파이썬 스칼라값(float등)으로 변환해줌\n",
    "\n",
    "2. crossentropy수행시 y의 값은 LongTensor (=int=정수형) 로 들어가야함.\n",
    "\n",
    "3. torch.max : 분류문제에서 정확도및 loss값 확인하려고 사용함\n",
    "\n",
    "4. - len(test_loader.dataset) : 전체 데이터 셋의 개수, \n",
    "   - len(test_loader) : 하나의 배치의 수.\n",
    "\n",
    "5. torchinfo : 모델정보를 볼수 있음. \n",
    "   - pip install torchinfo\n",
    "   - from torchinfo import summary\n",
    "   - summary(model_name , (batch size, input size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gesture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
